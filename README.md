# image_segmentation_project

Library Dependencies(Recommended):

*Python(3.7.6)

*numpy: NumPy, which stands for Numerical Python, is a library consisting of multidimensional array objects and a collection of routines for processing those arrays. Using NumPy, mathematical and logical operations on arrays can be performed.

*scipy: SciPy, a scientific library for Python. The SciPy library depends on NumPy, which provides convenient and fast N-dimensional array manipulation. The main reason for building the SciPy library is that, it should work with NumPy arrays. It provides many user-friendly and efficient numerical practices such as routines for numerical integration and optimization.

*pillow: Pillow is built on top of PIL (Python Image Library). PIL is one of the important modules for image processing in Python.Pillow module gives more functionalities, runs on all major operating system and support for python 3. It supports wide variety of images such as “jpeg”, “png”, “bmp”, “gif”, “ppm”, “tiff”. We can do opening, saving , manipulating etc.. on digital images using pillow module. Apart from basic image processing functionality, including point operations, filtering images using built-in convolution kernels, and color space conversions.

*matplotlib: Matplotlib is one of the most popular Python packages used for data visualization. It is a cross-platform library for making 2D plots from data in arrays. It provides an object-oriented API that helps in embedding plots in applications using Python GUI toolkits. It can be used in Python and IPython shells, Jupyter notebook and web application servers also.

*scikit-image: Scikit-learn is the most useful and robust library for machine learning in Python. It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence interface in Python. This library, which is largely written in Python, is built upon NumPy, SciPy and Matplotlib.

*tensorflow(1.13.1): TensorFlow is an open-source library developed by Google primarily for deep learning applications. It also supports traditional machine learning. TensorFlow was originally developed for large numerical computations without keeping deep learning in mind.

*keras(2.2.0): Keras is a minimalist Python library for deep learning that can run on top of Theano or TensorFlow. It was developed to make implementing deep learning models as fast and easy as possible for research and development.

*opencv-python: OpenCV is the huge open-source library for the computer vision, machine learning, and image processing. By using it, one can process images and videos to identify objects, faces, or even handwriting of a human. OpenCV-Python makes use of Numpy, which is a highly optimized library for numerical operations with a MATLAB-style syntax. All the OpenCV array structures are converted to and from Numpy arrays. This also makes it easier to integrate with other libraries that use Numpy such as SciPy and Matplotlib.

*h5py: The h5py package is a Pythonic interface to the HDF5 binary data format. It lets you store huge amounts of numerical data, and easily manipulate that data from NumPy. For example, you can slice into multi-terabyte datasets stored on disk, as if they were real NumPy arrays.

*imgaug:imgaug is a library for image augmentation in machine learning experiments. Image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset. Image data augmentation is used to expand the training dataset in order to improve the performance and ability of the model to generalize.

*cython: Superset of Python, Cython is much faster than Python. It improves Python code execution speed significantly by compiling Python code into C code. The compilation further helps developers to run the Python programs smoothly without deploying additional computing resources.

*ipython: Ipython is an alternative Python interpreter that provides improvements over the default Python interpreter. These improvements include syntax highlight, proper indentation, documentation, and much more. With iPython, you can also use Jupyter notebooks to create reports that contain live code, charts, and more.

*pycocotools-windows: COCO is a large image dataset designed for object detection, segmentation, person keypoints detection etc. This package provides Matlab, Python, and other APIs that assists in loading, parsing, and visualizing the annotations in COCO.
